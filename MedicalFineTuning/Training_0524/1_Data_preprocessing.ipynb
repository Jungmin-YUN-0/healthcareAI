{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woogoonkyu/anaconda3/envs/lora_null/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import default_data_collator, DataCollatorForLanguageModeling, AutoTokenizer\n",
    "from datasets import load_from_disk\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoConfig\n",
    "from torch.optim import AdamW  # ✅ 이걸로 교체\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "\n",
    "from datasets import load_from_disk\n",
    "data = load_from_disk('/nas_homes/projects/rapa/Dataset/data_updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'input', 'source'],\n",
       "        num_rows: 42782\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'input', 'source'],\n",
       "        num_rows: 10699\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다른 약물과의 상호작용을 고려하여 콜레스테롤 관리를 위해 프라바스타틴을 복용할 때 발생할 수 있는 부작용에 대해 자세히 설명하세요. 또한 누가 이 약을 복용하지 말아야 하는지 설명하세요.\n",
      "\n",
      "***Answer:\n",
      "프라바스타틴은 콜레스테롤 수치를 관리하는 데 일반적으로 사용되는 약물입니다. 다른 약물과 마찬가지로 잠재적인 부작용이 있을 수 있으며 다른 약물과 상호작용할 수도 있습니다.\n",
      "\n",
      "프라바스타틴의 가장 흔한 부작용으로는 두통, 근육통 또는 쇠약, 복통, 변비, 설사, 메스꺼움, 가벼운 피부 발진 등이 있습니다. 이러한 부작용은 대개 일시적이며 신체가 약물에 적응하면서 저절로 해결될 수 있습니다. 그러나 심각하거나 지속적인 부작용이 발생하면 의료진에게 문의하는 것이 중요합니다.\n",
      "\n",
      "약물 상호작용의 경우, 잠재적인 부작용을 피하기 위해 일반 의약품, 보충제, 허브 제품을 포함하여 복용 중인 모든 약물을 의료진에게 알려야 합니다. 특정 약물은 프라바스타틴과 상호작용하여 부작용 위험을 높이거나 효과를 감소시킬 수 있습니다.\n",
      "\n",
      "예를 들어, 다음과 같은 약물과 함께 복용할 경우 프라바스타틴을 피하거나 주의해서 사용해야 합니다.\n",
      "1. 사이클로스포린: 이 면역 억제제는 프라바스타틴의 혈중 농도를 증가시켜 부작용 위험을 증가시킬 수 있습니다.\n",
      "2. 젬피브로질: 젬피브로질과 프라바스타틴을 함께 복용하면 횡문근융해증과 같은 심각한 근육 문제가 발생할 위험이 높아질 수 있습니다.\n",
      "3. 와파린: 프라바스타틴은 와파린과 같은 항응고제의 효과를 높여 출혈의 위험을 증가시킬 수 있습니다.\n",
      "\n",
      "잠재적으로 상호작용할 수 있는 다른 약물이 있을 수 있습니다.\n",
      "프라바스타틴은 콜레스테롤 수치를 관리하는 데 일반적으로 사용되는 약물입니다. 다른 약물과 마찬가지로 잠재적인 부작용이 있을 수 있으며 다른 약물과 상호작용할 수도 있습니다.\n",
      "\n",
      "프라바스타틴의 가장 흔한 부작용으로는 두통, 근육통 또는 쇠약, 복통, 변비, 설사, 메스꺼움, 가벼운 피부 발진 등이 있습니다. 이러한 부작용은 대개 일시적이며 신체가 약물에 적응하면서 저절로 해결될 수 있습니다. 그러나 심각하거나 지속적인 부작용이 발생하면 의료진에게 문의하는 것이 중요합니다.\n",
      "\n",
      "약물 상호작용의 경우, 잠재적인 부작용을 피하기 위해 일반 의약품, 보충제, 허브 제품을 포함하여 복용 중인 모든 약물을 의료진에게 알려야 합니다. 특정 약물은 프라바스타틴과 상호작용하여 부작용 위험을 높이거나 효과를 감소시킬 수 있습니다.\n",
      "\n",
      "예를 들어, 다음과 같은 약물과 함께 복용할 경우 프라바스타틴을 피하거나 주의해서 사용해야 합니다.\n",
      "1. 사이클로스포린: 이 면역 억제제는 프라바스타틴의 혈중 농도를 증가시켜 부작용 위험을 증가시킬 수 있습니다.\n",
      "2. 젬피브로질: 젬피브로질과 프라바스타틴을 함께 복용하면 횡문근융해증과 같은 심각한 근육 문제가 발생할 위험이 높아질 수 있습니다.\n",
      "3. 와파린: 프라바스타틴은 와파린과 같은 항응고제의 효과를 높여 출혈의 위험을 증가시킬 수 있습니다.\n",
      "\n",
      "잠재적으로 상호작용할 수 있는 다른 약물이 있을 수 있습니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['train']['input'][0]), print(data['train']['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프라바스타틴은 콜레스테롤 수치를 관리하는 데 일반적으로 사용되는 약물입니다. 다른 약물과 마찬가지로 잠재적인 부작용이 있을 수 있으며 다른 약물과 상호작용할 수도 있습니다.\n",
      "\n",
      "프라바스타틴의 가장 흔한 부작용으로는 두통, 근육통 또는 쇠약, 복통, 변비, 설사, 메스꺼움, 가벼운 피부 발진 등이 있습니다. 이러한 부작용은 대개 일시적이며 신체가 약물에 적응하면서 저절로 해결될 수 있습니다. 그러나 심각하거나 지속적인 부작용이 발생하면 의료진에게 문의하는 것이 중요합니다.\n",
      "\n",
      "약물 상호작용의 경우, 잠재적인 부작용을 피하기 위해 일반 의약품, 보충제, 허브 제품을 포함하여 복용 중인 모든 약물을 의료진에게 알려야 합니다. 특정 약물은 프라바스타틴과 상호작용하여 부작용 위험을 높이거나 효과를 감소시킬 수 있습니다.\n",
      "\n",
      "예를 들어, 다음과 같은 약물과 함께 복용할 경우 프라바스타틴을 피하거나 주의해서 사용해야 합니다.\n",
      "1. 사이클로스포린: 이 면역 억제제는 프라바스타틴의 혈중 농도를 증가시켜 부작용 위험을 증가시킬 수 있습니다.\n",
      "2. 젬피브로질: 젬피브로질과 프라바스타틴을 함께 복용하면 횡문근융해증과 같은 심각한 근육 문제가 발생할 위험이 높아질 수 있습니다.\n",
      "3. 와파린: 프라바스타틴은 와파린과 같은 항응고제의 효과를 높여 출혈의 위험을 증가시킬 수 있습니다.\n",
      "\n",
      "잠재적으로 상호작용할 수 있는 다른 약물이 있을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "의대 입학부터 의사 면허 취득까지의 과정은 여러 단계로 나눌 수 있습니다:\n",
      "\n",
      "1. 학부 교육: 첫 번째 단계는 과학 또는 의학 관련 분야에서 학사 학위를 이수하는 것입니다. 이를 통해 의과대학에 필요한 기초 지식을 습득할 수 있습니다.\n",
      "\n",
      "2. 의과대학 입학 시험(MCAT): 의대 지망생은 학부 교육을 마친 후 MCAT를 치러야 합니다. 이 표준화된 시험은 과학적 개념에 대한 지식과 비판적 사고 능력을 평가합니다.\n",
      "\n",
      "3. 의과 대학 지원: 다음 단계는 의과대학에 지원하는 것입니다. 학생들은 일반적으로 미국 의과대학 지원 서비스(AMCAS)를 통해 지원서를 제출합니다. 지원서에는 자기소개서, 추천서, 성적증명서가 포함됩니다.\n",
      "\n",
      "4. 의과대학: 의대에 입학하면 학생들은 4년간의 엄격한 교육을 받게 됩니다. 커리큘럼에는 강의실 강의, 실험실 작업, 다양한 전문 분야에서 실습 경험을 쌓을 수 있는 임상 순환이 포함됩니다.\n",
      "\n",
      "5. 미국 의사 면허 시험(USMLE): 의과 대학 재학 중 학생들은 기초 과학 지식을 테스트하는 USMLE 1단계 시험을 통과해야 합니다. 그 후 임상 로테이션 기간 동안 2단계 임상 지식(CK) 및 2단계 임상 술기(CS) 시험에도 합격해야 합니다.\n",
      "\n",
      "6. 레지던트 수련: 의과대학을 졸업하면 졸업생은 레지던트 프로그램에 들어갑니다. 이 프로그램은 선택한 전문 분야에 따라 3년에서 7년까지 지속됩니다. 레지던트는 숙련된 의사의 감독 하에 일하면서 더 많은 실무 경험과 전문 교육을 받습니다.\n",
      "\n",
      "7.\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['input'][1].split('***Answer:')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "방사선학 보고서는 방사선과 전문의가 수행한 영상 검사에 대한 상세한 서면 해석입니다. 여기에는 다음 구성 요소가 포함됩니다.\n",
      "\n",
      "1. 환자 정보: 이 섹션에는 이름, 나이, 성별, 의료 기록 번호와 같은 환자의 식별 정보가 포함됩니다.\n",
      "\n",
      "2. 연구 세부 정보: X-레이, MRI, CT 스캔 또는 초음파 등 수행한 영상 검사 유형에 대한 정보를 제공합니다. 보고서에는 검사 날짜 및 시간도 언급됩니다.\n",
      "\n",
      "3. 기술: 이 섹션에서는 사용된 장비, 영상 매개변수 및 투여된 조영제 등 영상 검사가 수행된 방법에 대한 기술적 세부 사항을 설명합니다.\n",
      "\n",
      "4. 결과: 방사선 전문의가 검사에서 얻은 이미지를 해석하는 보고서의 주요 부분입니다. 여기에는 확인된 이상 또는 질병의 크기, 모양, 위치 및 특성을 포함하여 정상 또는 비정상 소견을 자세히 설명합니다. 또한 확인된 소견과 관련된 측정 또는 계산을 제공할 수도 있습니다.\n",
      "\n",
      "5. 인상: 이 섹션에서는 주요 결과를 요약하고 연구에 대한 전반적인 해석을 제공합니다. 여기에는 관찰된 결과를 설명할 수 있는 가능한 질환의 목록인 감별 진단이 포함될 수 있습니다.\n",
      "\n",
      "6. 권고: 방사선 전문의는 검사 결과에 따라 진단을 확인하거나 명확히 하는 데 도움이 되는 추가 진단 검사 또는 절차를 제안할 수 있습니다. 또한 후속 영상 검사를 권장하거나 추가 평가 또는 치료를 위해 환자를 다른 전문의에게 의뢰할 수도 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['output'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"Please read the following content and respond as a licensed medical doctor with expertise in the relevant field. Provide a detailed, accurate, and professional Answer. Please answer in korean. \\n***Content:\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "import random\n",
    "\n",
    "# 모델에 맞는 tokenizer 로딩\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"aaditya/Llama3-OpenBioLLM-8B\")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 데이터셋 로딩\n",
    "dataset = data\n",
    "\n",
    "def preprocess_function(example):\n",
    "    prompt = instruction + example[\"input\"]\n",
    "    answer = example[\"output\"]\n",
    "    answer_tag = \"***Answer:\\n\"\n",
    "    \n",
    "    # answer_tag 없으면 교체\n",
    "    if answer_tag not in prompt:\n",
    "        if \"Answer:\" in prompt:\n",
    "            prompt = prompt.replace(\"Answer:\", answer_tag)\n",
    "        else:\n",
    "            prompt +=  answer_tag\n",
    "            \n",
    "\n",
    "    # 전체 입력 문장\n",
    "\n",
    "\n",
    "    prompt = prompt.replace(\"***Answer:***Answer:\", \"***Answer:\") \n",
    "\n",
    "    # 1. 🪓 텍스트 기준으로 분리\n",
    "    prompt_part, answer_part = prompt.split(answer_tag, 1)\n",
    "\n",
    "    # 2. 🧼 정리된 텍스트\n",
    "    prompt_text = prompt_part + answer_tag  # 태그까지 포함\n",
    "    answer_text = answer_part.strip()       # 혹시 앞뒤 공백 제거\n",
    "\n",
    "    # 3. ✂️ 각각 토크나이즈\n",
    "    prompt_tokenized = tokenizer(prompt_text, add_special_tokens=False)\n",
    "    answer_tokenized = tokenizer(answer_text, add_special_tokens=False)\n",
    "\n",
    "    # 4. 🧩 전체 input_ids + attention_mask\n",
    "    input_ids = prompt_tokenized[\"input_ids\"] + answer_tokenized[\"input_ids\"]\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    # 5. 🔐 labels: prompt 구간은 -100, answer 구간은 그대로\n",
    "    labels = [-100] * len(prompt_tokenized[\"input_ids\"]) + answer_tokenized[\"input_ids\"]\n",
    "\n",
    "    # 6. 📏 max_length 맞춰 패딩/트렁케이션\n",
    "    max_length = 512\n",
    "    input_ids = input_ids[:max_length]\n",
    "    attention_mask = attention_mask[:max_length]\n",
    "    labels = labels[:max_length]\n",
    "\n",
    "    # 7. ⛑️ 패딩\n",
    "    pad_id = tokenizer.pad_token_id or tokenizer.eos_token_id\n",
    "    pad_len = max_length - len(input_ids)\n",
    "    input_ids += [pad_id] * pad_len\n",
    "    attention_mask += [0] * pad_len\n",
    "    labels += [-100] * pad_len\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 42782/42782 [00:55<00:00, 765.63 examples/s] \n",
      "Map: 100%|██████████| 10699/10699 [00:14<00:00, 748.24 examples/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"aaditya/Llama3-OpenBioLLM-8B\")\n",
    "\n",
    "num = 0\n",
    "name_lst = []\n",
    "\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "name = tokenizer.name_or_path.split('/')[0].replace('-','_')\n",
    "\n",
    "# 데이터셋 전체에 전처리 적용\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=False)\n",
    "\n",
    "# 원본 텍스트 열 제거\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"input\", \"output\", \"source\"])\n",
    "\n",
    "# 디스크에 저장\n",
    "if name in name_lst:\n",
    "    name = name + str(num)\n",
    "    num += 1\n",
    "else:\n",
    "    pass\n",
    "\n",
    "name_lst.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 42782\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 10699\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "프라바스타틴은 콜레스테롤 수치를 관리하는 데 일반적으로 사용되는 약물입니다. 다른 약물과 마찬가지로 잠재적인 부작용이 있을 수 있으며 다른 약물과 상호작용할 수도 있습니다.\n",
      "\n",
      "프라바스타틴의 가장 흔한 부작용으로는 두통, 근육통 또는 쇠약, 복통, 변비, 설사, 메스꺼움, 가벼운 피부 발진 등이 있습니다. 이러한 부작용은 대개 일시적이며 신체가 약물에 적응하면서 저절로 해결될 수 있습니다. 그러나 심각하거나 지속적인 부작용이 발생하면 의료진에게 문의하는 것이 중요합니다.\n",
      "\n",
      "약물 상호작용의 경우, 잠재적인 부작용을 피하기 위해 일반 의약품, 보충제, 허브 제품을 포함하여 복용 중인 모든 약물을 의료진에게 알려야 합니다. 특정 약물은 프라바스타틴과 상호작용하여 부작용 위험을 높이거나 효과를 감소시킬 수 있습니다.\n",
      "\n",
      "예를 들어, 다음과 같은 약물과 함께 복용할 경우 프라바스타틴을 피하거나 주의해서 사용해야 합니다.\n",
      "1. 사이클로스포린: 이 면역 억제제는 프라바스타틴의 혈중 농도를 증가시켜 부작용 위험을 증가시킬 수 있습니다.\n",
      "2. 젬피브로질: 젬피브로질과 프라바스타틴을 함께 복용하면 횡문근융해증과 같은 심각한 근육 문제가 발생할 위험이 높아질 수 있습니다.\n",
      "3. 와파린: 프라바스타틴은 와파린과 같은 항응고제의 효과를 높여 출혈의 위험을 증가시킬 수 있습니다.\n",
      "\n",
      "잠재적으로 상호작용할 수 있는 다른 약물이 있을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(data['train']['output'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 42782/42782 [00:23<00:00, 1783.96 examples/s]\n",
      "100%|██████████| 42782/42782 [00:00<00:00, 124107.59it/s]\n",
      "Map: 100%|██████████| 10699/10699 [00:06<00:00, 1779.48 examples/s]\n",
      "100%|██████████| 10699/10699 [00:00<00:00, 125877.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def find_invalid_samples(example, idx):\n",
    "    input_ids = example[\"input_ids\"]\n",
    "    masked_labels = example[\"labels\"]\n",
    "\n",
    "    # 기본적으로 길이 체크\n",
    "    if len(input_ids) != len(masked_labels):\n",
    "        return {\"invalid\": True}\n",
    "\n",
    "    # masked_labels의 유효 시작점 찾기\n",
    "    try:\n",
    "        masked_label_start_idx = next(i for i, v in enumerate(masked_labels) if v != -100)\n",
    "    except StopIteration:\n",
    "        return {\"invalid\": True}\n",
    "\n",
    "    # input_ids와 masked_labels 시작점 비교\n",
    "    if input_ids[masked_label_start_idx] != masked_labels[masked_label_start_idx]:\n",
    "        return {\"invalid\": True}\n",
    "\n",
    "    # 정상인 경우\n",
    "    return {\"invalid\": False}\n",
    "\n",
    "# 각 split별로 문제 인덱스 찾기\n",
    "invalid_indices = {}\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    result_dataset = tokenized_datasets[split].map(\n",
    "        find_invalid_samples,\n",
    "        with_indices=True,\n",
    "        batched=False,\n",
    "        remove_columns=tokenized_datasets[split].column_names\n",
    "    )\n",
    "\n",
    "    # 문제가 있는 샘플의 인덱스만 추출\n",
    "    invalid_idx = [i for i, example in tqdm(enumerate(result_dataset), total=len(result_dataset)) if example[\"invalid\"]]\n",
    "    invalid_indices[split] = invalid_idx\n",
    "\n",
    "# 최종 결과 출력\n",
    "# print(\"🚨 문제가 있는 샘플 인덱스 결과:\")\n",
    "# print(invalid_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_preprocessed_sample(sample, tokenizer):\n",
    "    input_ids = sample[\"input_ids\"]\n",
    "    labels = sample[\"labels\"]\n",
    "\n",
    "    # 🔍 전체 디코딩 (input_ids)\n",
    "    decoded_input = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "\n",
    "    # 🔍 정답 디코딩 (labels 중 -100 제외)\n",
    "    label_ids = [t for t in labels if t != -100]\n",
    "    decoded_label = tokenizer.decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # 🔢 시각적으로 보기 좋게 정리\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🧾 Full input (input_ids):\")\n",
    "    print(decoded_input)\n",
    "    print(\"-\" * 60)\n",
    "    print(\"🎯 Target only (labels):\")\n",
    "    print(decoded_label)\n",
    "    print(\"=\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=4): 100%|██████████| 42782/42782 [00:05<00:00, 8395.16 examples/s] \n",
      "Filter (num_proc=4): 100%|██████████| 10699/10699 [00:01<00:00, 7821.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 33298\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 8327\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def is_valid_sample(example):\n",
    "    input_ids = example[\"input_ids\"]\n",
    "    masked_labels = example[\"labels\"]\n",
    "\n",
    "    # 길이 체크\n",
    "    if len(input_ids) != len(masked_labels):\n",
    "        return False\n",
    "\n",
    "    # masked_labels의 유효 시작점 찾기\n",
    "    try:\n",
    "        masked_label_start_idx = next(i for i, v in enumerate(masked_labels) if v != -100)\n",
    "    except StopIteration:\n",
    "        return False\n",
    "\n",
    "    # 시작점 비교\n",
    "    if input_ids[masked_label_start_idx] != masked_labels[masked_label_start_idx]:\n",
    "        return False\n",
    "\n",
    "    # ✅ 모든 라벨이 -100인지 체크\n",
    "    if all(v == -100 for v in masked_labels):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# 문제가 있는 샘플을 제거한 새로운 데이터셋 만들기\n",
    "filtered_datasets = DatasetDict()\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    filtered_datasets[split] = tokenized_datasets[split].filter(\n",
    "        is_valid_sample,\n",
    "        num_proc=4,\n",
    "    )\n",
    "\n",
    "# 결과 출력\n",
    "print(filtered_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 33298/33298 [00:19<00:00, 1729.96 examples/s]  \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 8327/8327 [00:04<00:00, 1717.55 examples/s] \n"
     ]
    }
   ],
   "source": [
    "# filtered_datasets.save_to_disk('/nas_homes/projects/rapa/Dataset/filtered_updated_datasets_512_instruction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_null",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
