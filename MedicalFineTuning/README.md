# OpenBioLLM-Korean (Preview)ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ í•œêµ­ì–´ Finetuning

## Requirements

* torch
* transformers
* fire

ì•„ë˜ì™€ ê°™ì€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜

```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118 # change to your CUDA version
pip install pandas datasets transformers peft trl huggingface_hub bitsandbytes
```

## Data

  `KoAlpaca_v1.1_medical.jsonl`: KoAlpaca ë°ì´í„°ì…‹ì—ì„œ ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ ë° ë‹µë³€ë§Œì„ ì¶”ì¶œí•œ ë°ì´í„°ì…‹

## Finetuning

* `--data_path`: í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ê²½ë¡œ (JSONL í˜•ì‹).
* `--base_model`: ì‚¬ì „ í•™ìŠµëœ í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸ ê²½ë¡œ.
* `--output_dir`: í•™ìŠµ ê³¼ì •ì—ì„œì˜ Outputì„ ì €ì¥í•  ê²½ë¡œ
* í•™ìŠµëœ ëª¨ë¸ì€ `--base_model`ê³¼ ê°™ì€ ê²½ë¡œì— `-InstructFT`ê°€ ì¶”ê°€ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨

```bash
python script.py --data_path './KoAlpaca_v1.1_medical.jsonl' --base_model '../ChatVector/ckpt/Llama-3-8B-OpenBioLLM-Korean' --output_dir './outputs'
```



# 05/24

## <RAPA ì¸ìˆ˜ì¸ê³„>
-	ëª¨ë“  í´ë”ëŠ” /nas_homes/projects/rapaì— ìœ„ì¹˜.

-	
## ğŸ“ í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ì•ˆë‚´

ë³¸ ì €ì¥ì†Œì˜ ì£¼ìš” í´ë” ë° íŒŒì¼ êµ¬ì¡°ì— ëŒ€í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ê° í´ë”ëŠ” ëª¨ë¸ í•™ìŠµ, ë°ì´í„°ì…‹ ê´€ë¦¬, ê²°ê³¼ í™•ì¸ ë“±ì„ ìœ„í•´ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

### 1. `Chatvector/`
Chatvector ê´€ë ¨ ëª¨ë¸ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤.  
- Chatvector ëª¨ë¸ ì €ì¥  
- ìƒì„± ë°©ë²•ì€ [ê³µì‹ GitHub ì €ì¥ì†Œ](https://github.com/Marker-Inc-Korea/COT_steering/tree/main) ì°¸ê³ 

---

### 2. `Dataset/`
ëª¨ë¸ í•™ìŠµ ë° íŒŒì¸íŠœë‹ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹ë“¤ì´ í¬í•¨ëœ ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤.

- **`Blossom/`**  
  Blossom ëª¨ë¸ íŒŒì¸íŠœë‹ìš© ë°ì´í„°ì…‹

- **`Data_updated/`**  
  ì˜ë£Œ ì¦ê°• ë°ì´í„°ì…‹ (ì„œìš¸ëŒ€í•™êµ + ê¸°ì¡´ ë°ì´í„° í˜¼í•©)  
  â€» ìƒì„¸í•œ ë‚´ìš©ì€ ë‚´ë¶€ PPT ì°¸ê³ 

- **`Data_update_512/`**  
  `Data_updated` ë°ì´í„°ë¥¼ 512 í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•œ ë²„ì „

---

### 3. `Results/`
ì§€ê¸ˆê¹Œì§€ ì§„í–‰ëœ ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ë””ë ‰í† ë¦¬ì…ë‹ˆë‹¤.

- BERT Score, BLEU ë“± ë‹¤ì–‘í•œ í‰ê°€ ì§€í‘œ í¬í•¨  
- CoT (Chain-of-Thought) ê²°ê³¼ëŠ” [Steering Vector ì €ì¥ì†Œ](https://github.com/Marker-Inc-Korea/COT_steering/tree/main) ì°¸ê³ 

---

### 4. `Code/`
ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ ë° í…ìŠ¤íŠ¸ ìƒì„± ë“±ì— ê´€ë ¨ëœ ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

- **`Data_checker/`**  
  ì´ˆê¸°ì— ì œê³µë˜ì–´ì§„ ë°ì´í„° ì „ì²˜ë¦¬ ì½”ë“œ  
  (`Data_updated`ì— ì´ë¯¸ ë°˜ì˜ ì™„ë£Œ)

- **`LoRA_first.py`**  
  OpenBioLLM ëª¨ë¸ í•™ìŠµ ì½”ë“œ

- **`Exaone.py`**  
  Exaone ëª¨ë¸ í•™ìŠµ ì½”ë“œ  
  â€» ëª¨ë¸ íŒŒì¼ì€ ìš©ëŸ‰ ë¬¸ì œë¡œ ì‚­ì œë¨ â†’ ì¬í•™ìŠµ í•„ìš”

- **`ds_config.json`**  
  Deepspeed ì„¤ì • íŒŒì¼

- **`Generation1.ipynb`**  
  ì‹¤ì œ í…ìŠ¤íŠ¸ ìƒì„± ì½”ë“œ

- **ê¸°íƒ€ í´ë”**  
  ê¶Œí•œ ë¬¸ì œë¡œ ì¸í•´ ì œê±°í•˜ì§€ ëª»í•œ í´ë” ì¼ë¶€ ì¡´ì¬


## Generation ê²°ê³¼í‘œ

### ğŸ§¾ Dialogue Generation Task Evaluation Results

| Model | RoBERTaScore | BERTScore | BLEU | ROUGE-1 | ROUGE-2 | ROUGE-L | METEOR |
|-------|--------------|-----------|------|----------|----------|----------|--------|
| OpenBiollm | â€“ | 0.0223 | 0.0017 | 0.0015 | 0.0004 | 0.0015 | 0.0048 |
| OpenBiollm + chatvector | 0.5571 | 0.0570 | 0.0954 | 0.0493 | 0.0903 | 0.0903 | 0.2267 |
| LGAI-EXAONE-7.8B (instruct) | 0.7480 | 0.5994 | 0.0579 | 0.1888 | 0.0918 | 0.1757 | 0.2619 |
| Qwen 2.5 7B Vanilla | 0.7391 | 0.5665 | 0.0724 | 0.1388 | 0.0767 | 0.1341 | 0.2354 |
| yanolja/EEVE-Korean-10.8B-v1.0 | 0.7637 | 0.6238 | 0.0623 | 0.1772 | 0.1010 | 0.1682 | 0.2397 |
| OpenBioLLM + chatvector + AdaLoRA (Instruct) | 0.5567 | 0.0571 | 0.0958 | 0.0501 | 0.0907 | 0.2265 | 0.2265 |
| OpenBioLLM + chatvector + LoRA (Instruct) | 0.7397 | 0.5923 | 0.0742 | 0.1505 | 0.0906 | 0.1449 | 0.2306 |
| OpenBioLLM + chatvector + LoRA (Instruct) + CoT (k=4) | 0.7629 | 0.6186 | 0.0795 | 0.1938 | 0.1104 | 0.1833 | 0.2985 |
| OpenBioLLM + chatvector + LoRA (Instruct) + CoT (k=10) | 0.7602 | 0.6153 | 0.0782 | 0.1922 | 0.1070 | 0.1813 | 0.2955 |
| Qwen 2.5 7B Instruct | â€“ | 0.5984 | 0.0808 | 0.1782 | 0.0959 | 0.1688 | 0.2741 |
| Qwen 2.5 7B Vanilla | 0.7391 | 0.5665 | 0.0724 | 0.1388 | 0.0767 | 0.1341 | 0.2354 |

> `â€“` indicates missing RoBERTaScore values for that model.

