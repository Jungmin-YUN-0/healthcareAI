{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76f78e9",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "- QA Task\n",
    "    - QA Task Train / Test split\n",
    "    - QA instruction prompt\n",
    "    - 추가 전처리\n",
    "    \n",
    "- Dialogue Task\n",
    "    - Dialogue Task Train / Test split\n",
    "    - [(Input) : Client - Doctor - Client || (Output) : Doctor]  Dilaogue 데이터셋 분리\n",
    "    - Dialogue Instruction Prompt\n",
    "    - 추가 전처리\n",
    "\n",
    "- Total Dataset\n",
    "    - 이 2개의 데이터 셋을 concatenate, 추가 전처리 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16b00d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woogoonkyu/anaconda3/envs/next/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from transformers import (\n",
    "    AutoConfig, AutoTokenizer, DataCollatorForLanguageModeling, \n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import Adafactor\n",
    "import json\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b434c29c",
   "metadata": {},
   "source": [
    "# Dialogue Task\n",
    "\n",
    "- Train, Test 분리 및 Instruction Prompt 포함되게 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c915323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"squarelike/ko_medical_chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35f01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def extract_sft_pairs(dataset):\n",
    "    new_data = {\"input\": [], \"output\": [], \"all_dialogue\": []}\n",
    "\n",
    "    for example in dataset:\n",
    "        conv = example[\"conversations\"]  # 전체 메시지 리스트\n",
    "\n",
    "        # 전체 대화를 텍스트로 합쳐놓기\n",
    "        full_dialogue = \"\"\n",
    "        for turn in conv:\n",
    "            speaker = turn['from'].capitalize()\n",
    "            message = turn['value']\n",
    "            full_dialogue += f\"{speaker}: {message}\\n\"\n",
    "\n",
    "        for i in range(3, len(conv)):\n",
    "            try:\n",
    "                if (conv[i-3]['from'] == 'client' and\n",
    "                    conv[i-2]['from'] == 'doctor' and\n",
    "                    conv[i-1]['from'] == 'client' and\n",
    "                    conv[i]['from'] == 'doctor'):\n",
    "\n",
    "                    input_text = (\n",
    "                        f\"Client: {conv[i-3]['value']}\\n\"\n",
    "                        f\"Doctor: {conv[i-2]['value']}\\n\"\n",
    "                        f\"Client: {conv[i-1]['value']}\"\n",
    "                    )\n",
    "                    output_text = f\"Doctor: {conv[i]['value']}\"\n",
    "\n",
    "                    new_data[\"input\"].append(input_text)\n",
    "                    new_data[\"output\"].append(output_text)\n",
    "                    new_data[\"all_dialogue\"].append(full_dialogue.strip())  # 전체 대화도 추가\n",
    "            except (IndexError, KeyError):\n",
    "                continue\n",
    "\n",
    "    return Dataset.from_dict(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93b7ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "sft_dataset = extract_sft_pairs(ds['train'])\n",
    "Dialogue_dataset = sft_dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8fef99",
   "metadata": {},
   "source": [
    "### Template 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19996bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a medical professional proficient in both Korean and English.\n",
    "Your task is to carefully read the conversation between a Client and a Doctor, \n",
    "then predict the next response from the Doctor in a professional and empathetic manner.\n",
    "\n",
    "Please respond in **Korean** only.\n",
    "\n",
    "Now produce the next Doctor response to the Client’s last question.\n",
    "Return your answer in Korean.\n",
    "\n",
    "***Conversation:\n",
    "{conversation}\n",
    "\n",
    "***Answer:\n",
    "{Answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f48895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9484/9484 [00:00<00:00, 13363.85 examples/s]\n",
      "Map: 100%|██████████| 2372/2372 [00:00<00:00, 16230.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용 함수\n",
    "def apply_template(example):\n",
    "    formatted_input = template.format(\n",
    "        conversation=example[\"input\"],\n",
    "        Answer=example[\"output\"]\n",
    "    )\n",
    "    return {\n",
    "        \"input\": formatted_input,\n",
    "        \"output\": example[\"output\"]\n",
    "    }\n",
    "\n",
    "# train, test 각각 템플릿 적용\n",
    "new_train = Dialogue_dataset[\"train\"].map(apply_template)\n",
    "new_test = Dialogue_dataset[\"test\"].map(apply_template)\n",
    "\n",
    "# 새 DatasetDict로 묶기\n",
    "templated_dataset = DatasetDict({\n",
    "    \"train\": new_train,\n",
    "    \"test\": new_test\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddf2d2",
   "metadata": {},
   "source": [
    "# QA Task\n",
    "\n",
    "- Train, Test 분리\n",
    "- Instruction Prompt 포함\n",
    "- 일부 데이터 한국어로 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18b23b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dentist = load_dataset(\"sean0042/KorMedMCQA\", 'dentist') # 추가 전처리 필요\n",
    "doctor = load_dataset(\"sean0042/KorMedMCQA\", 'doctor') # 추가 전처리 필요\n",
    "nurse = load_dataset(\"sean0042/KorMedMCQA\", 'nurse') # 추가 전처리 필요\n",
    "pharm = load_dataset(\"sean0042/KorMedMCQA\", 'pharm') # 추가 전처리 필요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7692ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_all(all_datasets):\n",
    "    combined_dataset = concatenate_datasets([\n",
    "        all_datasets[\"train\"],\n",
    "        all_datasets[\"dev\"],\n",
    "        all_datasets[\"test\"],\n",
    "        all_datasets[\"fewshot\"]\n",
    "    ])\n",
    "\n",
    "    return combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0699c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dentist_all = concatenate_all(dentist)\n",
    "doctor_all = concatenate_all(doctor)\n",
    "nurse_all = concatenate_all(nurse)\n",
    "pharm_all = concatenate_all(pharm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d48220f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['subject', 'year', 'period', 'q_number', 'question', 'A', 'B', 'C', 'D', 'E', 'answer', 'cot'],\n",
       "    num_rows: 2494\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctor_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3a101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = concatenate_datasets([dentist_all, doctor_all, nurse_all, pharm_all])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a161ac",
   "metadata": {},
   "source": [
    "### Train Test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b944108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "\n",
    "split = combined_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "final_datasets = {\n",
    "    \"train\": split[\"train\"],\n",
    "    \"test\": split[\"test\"]\n",
    "}\n",
    "\n",
    "final_datasets = DatasetDict(final_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70bb133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# 필요한 열만 유지\n",
    "columns_to_keep = ['question', 'A', 'B', 'C', 'D', 'E', 'answer']\n",
    "\n",
    "final_datasets = DatasetDict({\n",
    "    split: dataset.remove_columns([col for col in dataset.column_names if col not in columns_to_keep])\n",
    "    for split, dataset in final_datasets.items()\n",
    "})\n",
    "\n",
    "# 'answer' 컬럼을 'output'으로 이름 변경\n",
    "QA_dataset = DatasetDict({\n",
    "    split: dataset.rename_column(\"answer\", \"output\")\n",
    "    for split, dataset in final_datasets.items()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e1027",
   "metadata": {},
   "source": [
    "### Instruction Prompt 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0681838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LangChain의 프롬프트 템플릿 유지\n",
    "qa_template = \"\"\"\n",
    "You are a medical professional proficient in both Korean and English. \n",
    "Your task is to carefully analyze a given medical question and its five answer choices, \n",
    "then provide the correct answer.\n",
    "The answer choice will always follow the fixed format of Choice 1, Choice 2, Choice 3, Choice 4, Choice 5.\n",
    "Return the response in the following format:\n",
    "Choice answer\n",
    "\n",
    "Now, analyze the following medical question and return the answer.\n",
    "\n",
    "Question: {question}\n",
    "Choice 1: {A}\n",
    "Choice 2: {B}\n",
    "Choice 3: {C}\n",
    "Choice 4: {D}\n",
    "Choice 5: {E}\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71338841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_example_with_answer_text(example):\n",
    "    # 보기 딕셔너리\n",
    "    choices = {\n",
    "        \"Choice 1\": example[\"A\"],\n",
    "        \"Choice 2\": example[\"B\"],\n",
    "        \"Choice 3\": example[\"C\"],\n",
    "        \"Choice 4\": example[\"D\"],\n",
    "        \"Choice 5\": example[\"E\"]\n",
    "    }\n",
    "\n",
    "    # 정답 텍스트 붙이기\n",
    "    choice_only = example[\"output\"]  # 예: \"Choice 2\"\n",
    "    full_answer = f\"{choice_only}, {choices.get(choice_only, '')}\"\n",
    "\n",
    "    # 프롬프트 구성\n",
    "    prompt = qa_template.format(\n",
    "        question=example[\"question\"],\n",
    "        A=example[\"A\"],\n",
    "        B=example[\"B\"],\n",
    "        C=example[\"C\"],\n",
    "        D=example[\"D\"],\n",
    "        E=example[\"E\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input\": prompt,\n",
    "        \"output\": full_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4b7c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 각각 템플릿 + 정답 텍스트 포함 변환\n",
    "formatted_train = QA_dataset[\"train\"].map(format_qa_example_with_answer_text)\n",
    "formatted_test = QA_dataset[\"test\"].map(format_qa_example_with_answer_text)\n",
    "\n",
    "# A~E는 필요 없으니 제거\n",
    "formatted_QA_dataset = DatasetDict({\n",
    "    \"train\": formatted_train.remove_columns([\"A\", \"B\", \"C\", \"D\", \"E\"]),\n",
    "    \"test\": formatted_test.remove_columns([\"A\", \"B\", \"C\", \"D\", \"E\"]),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039374e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'output', 'input'],\n",
       "        num_rows: 5991\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'output', 'input'],\n",
       "        num_rows: 1498\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_QA_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a9936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eef32ce4",
   "metadata": {},
   "source": [
    "# Total Dataset\n",
    "\n",
    "- Dialogue / QA Dataset을 한꺼번에 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28813711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source 컬럼 추가 함수\n",
    "def add_source_column(dataset, source_label):\n",
    "    return dataset.map(lambda example: {**example, \"source\": source_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07a98a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9484/9484 [00:00<00:00, 19120.46 examples/s]\n",
      "Map: 100%|██████████| 2372/2372 [00:00<00:00, 20536.76 examples/s]\n",
      "Map: 100%|██████████| 5991/5991 [00:00<00:00, 23947.40 examples/s]\n",
      "Map: 100%|██████████| 1498/1498 [00:00<00:00, 24267.47 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "# Dialogue\n",
    "templated_train = add_source_column(templated_dataset[\"train\"], \"dialogue\")\n",
    "templated_test = add_source_column(templated_dataset[\"test\"], \"dialogue\")\n",
    "\n",
    "# QA\n",
    "qa_train = add_source_column(formatted_QA_dataset[\"train\"], \"qa\")\n",
    "qa_test = add_source_column(formatted_QA_dataset[\"test\"], \"qa\")\n",
    "\n",
    "# 합치기\n",
    "combined_train = concatenate_datasets([templated_train, qa_train])\n",
    "combined_test = concatenate_datasets([templated_test, qa_test])\n",
    "\n",
    "# 최종 DatasetDict\n",
    "combined_dataset = DatasetDict({\n",
    "    \"train\": combined_train,\n",
    "    \"test\": combined_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56989ec8",
   "metadata": {},
   "source": [
    "### 추가 전처리\n",
    "\n",
    "- Doctor, Client 의미 제거\n",
    "- 몇몇 단어 한국어 변환 및 표현 명확화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88662f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def transform_prompt(prompt: str) -> str:\n",
    "    # 추가할 지침 문장\n",
    "    role_instruction = \"You will always respond as the doctor, and your answer must be written in Korean only.\\n\\n\"\n",
    "\n",
    "    # 1. '***Conversation:' 위치 찾기\n",
    "    parts = prompt.split('***Conversation:')\n",
    "    if len(parts) != 2:\n",
    "        return prompt  # 변환할 수 없는 구조는 그대로 반환\n",
    "\n",
    "    header, conversation = parts\n",
    "\n",
    "    # 2. Client:, Doctor: 라벨 제거\n",
    "    conversation_cleaned = re.sub(r'^(Client|Doctor):\\s*', '', conversation, flags=re.MULTILINE)\n",
    "\n",
    "    # 3. 역할 문장을 Conversation 위에 삽입\n",
    "    transformed_prompt = header.strip() + \"\\n\\n\" + role_instruction + \"***Conversation:\" + conversation_cleaned\n",
    "\n",
    "    return transformed_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0372977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_after_answer(example):\n",
    "    if example['source'] == 'dialogue':\n",
    "        example['input'] = transform_prompt(example['input'])\n",
    "        example['output'] = re.sub(r'^(Client|Doctor):\\s*', '', example['output'], flags=re.MULTILINE)\n",
    "\n",
    "    if example['source'] == 'qa':\n",
    "        example['input'] = example['input'].replace('Choice','선택')\n",
    "        example['input'] = example['input'].replace('Answer:','***Answer:').replace('Question:','***Question:' )\n",
    "        example['input'] = example['input'].strip()\n",
    "        example['output'] = example['output'].replace('Choice','선택').strip()\n",
    "        \n",
    "    if '***Answer:' in example['input']:\n",
    "        # '***Answer:'까지만 남기고 뒷부분 삭제\n",
    "        idx = example['input'].index('***Answer:') + len('***Answer:')\n",
    "        example['input'] = example['input'][:idx].strip()\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55ebb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15475/15475 [00:00<00:00, 15599.41 examples/s]\n",
      "Map: 100%|██████████| 3870/3870 [00:00<00:00, 16011.54 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 15475/15475 [00:03<00:00, 4799.41 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3870/3870 [00:00<00:00, 4777.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 적용\n",
    "train_cleaned = combined_dataset['train'].map(truncate_after_answer)\n",
    "test_cleaned = combined_dataset['test'].map(truncate_after_answer)\n",
    "\n",
    "# 다시 DatasetDict로\n",
    "cleaned_dataset = DatasetDict({\n",
    "    'train': train_cleaned,\n",
    "    'test': test_cleaned\n",
    "})\n",
    "\n",
    "\n",
    "cleaned_dataset.save_to_disk(\"/nas_homes/projects/rapa/Dataset/cleaned_dataset_with_answer_tag_new\") ## QA / Dialogue 데이터셋 모두 저장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "next",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
