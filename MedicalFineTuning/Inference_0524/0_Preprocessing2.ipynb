{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/woogoonkyu/anaconda3/envs/lora_null/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import (\n",
    "    AutoConfig, AutoTokenizer, DataCollatorForLanguageModeling, \n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import Adafactor\n",
    "import json\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 21:09:45,538\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch._dynamo\n",
    "\n",
    "# torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LangChain의 프롬프트 템플릿 유지\n",
    "qa_template = \"\"\"\n",
    "You are a medical professional proficient in both Korean and English. \n",
    "Your task is to carefully analyze a given medical question and its five answer choices, \n",
    "then provide the correct answer.\n",
    "The answer choice will always follow the fixed format of Choice 1, Choice 2, Choice 3, Choice 4, Choice 5.\n",
    "Return the response in the following format:\n",
    "Choice answer\n",
    "\n",
    "Now, analyze the following medical question and return the answer.\n",
    "\n",
    "Question: {question}\n",
    "Choice 1: {A}\n",
    "Choice 2: {B}\n",
    "Choice 3: {C}\n",
    "Choice 4: {D}\n",
    "Choice 5: {E}\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk,DatasetDict, Dataset\n",
    "\n",
    "QA_dataset = load_from_disk(\"QA_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_example_with_answer_text(example):\n",
    "    # 보기 딕셔너리\n",
    "    choices = {\n",
    "        \"Choice 1\": example[\"A\"],\n",
    "        \"Choice 2\": example[\"B\"],\n",
    "        \"Choice 3\": example[\"C\"],\n",
    "        \"Choice 4\": example[\"D\"],\n",
    "        \"Choice 5\": example[\"E\"]\n",
    "    }\n",
    "\n",
    "    # 정답 텍스트 붙이기\n",
    "    choice_only = example[\"output\"]  # 예: \"Choice 2\"\n",
    "    full_answer = f\"{choice_only}, {choices.get(choice_only, '')}\"\n",
    "\n",
    "    # 프롬프트 구성\n",
    "    prompt = qa_template.format(\n",
    "        question=example[\"input\"],\n",
    "        A=example[\"A\"],\n",
    "        B=example[\"B\"],\n",
    "        C=example[\"C\"],\n",
    "        D=example[\"D\"],\n",
    "        E=example[\"E\"]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input\": prompt,\n",
    "        \"output\": full_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/5991 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5991/5991 [00:00<00:00, 14693.53 examples/s]\n",
      "Map: 100%|██████████| 1498/1498 [00:00<00:00, 14976.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# train/test 각각 템플릿 + 정답 텍스트 포함 변환\n",
    "formatted_train = QA_dataset[\"train\"].map(format_qa_example_with_answer_text)\n",
    "formatted_test = QA_dataset[\"test\"].map(format_qa_example_with_answer_text)\n",
    "\n",
    "# A~E는 필요 없으니 제거\n",
    "formatted_QA_dataset = DatasetDict({\n",
    "    \"train\": formatted_train.remove_columns([\"A\", \"B\", \"C\", \"D\", \"E\"]),\n",
    "    \"test\": formatted_test.remove_columns([\"A\", \"B\", \"C\", \"D\", \"E\"]),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a medical professional proficient in both Korean and English. \\nYour task is to carefully analyze a given medical question and its five answer choices, \\nthen provide the correct answer.\\nThe answer choice will always follow the fixed format of Choice 1, Choice 2, Choice 3, Choice 4, Choice 5.\\nReturn the response in the following format:\\nChoice answer\\n\\nNow, analyze the following medical question and return the answer.\\n\\nQuestion: 세균의 성장에 필요한 철 이온을 고갈시켜 영양면역 (nutritional immunity) 기능을 갖는 타액 내 단백질은?\\nChoice 1: 스타테린(statherin)\\nChoice 2: 락토페린(lactoferrin)\\nChoice 3: 라이소자임(lysozyme)\\nChoice 4: 트랜스페린(transferrin)\\nChoice 5: 면역글로불린(immunoglobulin)\\nAnswer: \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_QA_dataset[\"train\"][0][\"input\"]\n",
    "# → \"Choice 2, methyl mercaptan\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_QA_dataset.save_to_disk(\"formatted_medical_QA_with_answers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 5991\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output'],\n",
       "        num_rows: 1498\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_QA_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialogue Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a medical professional proficient in both Korean and English.\n",
    "Your task is to carefully read the conversation between a Client and a Doctor, \n",
    "then predict the next response from the Doctor in a professional and empathetic manner.\n",
    "\n",
    "Please respond in **Korean** only.\n",
    "\n",
    "Now produce the next Doctor response to the Client’s last question.\n",
    "Return your answer in Korean.\n",
    "\n",
    "***Conversation:\n",
    "{conversation}\n",
    "\n",
    "***Answer:\n",
    "{Answer}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'all_dialogue'],\n",
       "        num_rows: 9484\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'output', 'all_dialogue'],\n",
       "        num_rows: 2372\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk,DatasetDict, Dataset\n",
    "\n",
    "Dialogue_dataset = load_from_disk(\"Dialogue_data_all\")\n",
    "\n",
    "Dialogue_dataset['train']['input'][0], Dialogue_dataset['train']['output'][0]\n",
    "\n",
    "Dialogue_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9484/9484 [00:00<00:00, 25362.15 examples/s]\n",
      "Map: 100%|██████████| 2372/2372 [00:00<00:00, 27566.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 적용 함수\n",
    "def apply_template(example):\n",
    "    formatted_input = template.format(\n",
    "        conversation=example[\"input\"],\n",
    "        Answer=example[\"output\"]\n",
    "    )\n",
    "    return {\n",
    "        \"input\": formatted_input,\n",
    "        \"output\": example[\"output\"]\n",
    "    }\n",
    "\n",
    "# train, test 각각 템플릿 적용\n",
    "new_train = Dialogue_dataset[\"train\"].map(apply_template)\n",
    "new_test = Dialogue_dataset[\"test\"].map(apply_template)\n",
    "\n",
    "# 새 DatasetDict로 묶기\n",
    "templated_dataset = DatasetDict({\n",
    "    \"train\": new_train,\n",
    "    \"test\": new_test\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 (선택사항)\n",
    "# templated_dataset.save_to_disk(\"templated_doctor_dialogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source 컬럼 추가 함수\n",
    "def add_source_column(dataset, source_label):\n",
    "    return dataset.map(lambda example: {**example, \"source\": source_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9484/9484 [00:00<00:00, 19899.58 examples/s]\n",
      "Map: 100%|██████████| 2372/2372 [00:00<00:00, 21368.07 examples/s]\n",
      "Map: 100%|██████████| 5991/5991 [00:00<00:00, 35841.18 examples/s]\n",
      "Map: 100%|██████████| 1498/1498 [00:00<00:00, 34586.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets, load_dataset\n",
    "\n",
    "# Dialogue\n",
    "templated_train = add_source_column(templated_dataset[\"train\"], \"dialogue\")\n",
    "templated_test = add_source_column(templated_dataset[\"test\"], \"dialogue\")\n",
    "\n",
    "# QA\n",
    "qa_train = add_source_column(formatted_QA_dataset[\"train\"], \"qa\")\n",
    "qa_test = add_source_column(formatted_QA_dataset[\"test\"], \"qa\")\n",
    "\n",
    "# 합치기\n",
    "combined_train = concatenate_datasets([templated_train, qa_train])\n",
    "combined_test = concatenate_datasets([templated_test, qa_test])\n",
    "\n",
    "# 최종 DatasetDict\n",
    "combined_dataset = DatasetDict({\n",
    "    \"train\": combined_train,\n",
    "    \"test\": combined_test\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue\n"
     ]
    }
   ],
   "source": [
    "print(combined_dataset[\"train\"][0][\"source\"])  # 'dialogue' 또는 'qa'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 15475/15475 [00:00<00:00, 236551.36 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3870/3870 [00:00<00:00, 338476.03 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# combined_dataset.save_to_disk(\"combined_dataset_short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_null",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
